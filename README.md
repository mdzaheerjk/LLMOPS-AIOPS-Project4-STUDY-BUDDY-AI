# ğŸ¤– LLMOps & AIOps Project 4: Study Buddy AI

![LLMOps](https://img.shields.io/badge/LLMOPs-AIOps-blueviolet)
![Python](https://img.shields.io/badge/Python-3.12%2B-brightgreen)
![Docker](https://img.shields.io/badge/Docker-Ready-blue)
![Kubernetes](https://img.shields.io/badge/Kubernetes-Deploy-blue)
![Jenkins](https://img.shields.io/badge/Jenkins-CI%2FCD-success)
![License](https://img.shields.io/badge/License-GPL--3.0-orange)

A modern, production-grade AI-powered study assistant built with LLMOps and AIOps best practices. Study Buddy AI leverages Large Language Models, modular prompt engineering, and scalable infrastructure to generate personalized study questions, explanations, and learning resources. The system is designed for extensibility, observability, and robust cloud-native deployment.

> ğŸ“ **Repository:** `LLMOPS-AIOPS-Project4-STUDY-BUDDY-AI`

---

## ğŸš€ Project Highlights

- ğŸ“ **AI Study Assistant:** Generate personalized study questions, quizzes, and learning content using LLMs.
- ğŸ”— **Prompt Engineering:** Modular, extensible prompt templates for flexible content generation.
- ğŸ—ï¸ **Scalable Pipeline:** Modular codebase, config-driven, and ready for production.
- ğŸ³ **Dockerized:** Easy local or cloud deployment with Docker.
- â˜¸ï¸ **Kubernetes-Ready:** Includes manifests for scalable deployment.
- ğŸ”„ **CI/CD with Jenkins:** Automated build, test, and deploy pipeline.
- ğŸ“‘ **Full Documentation:** See `FULL_DOCUMENTATION.md` for technical and usage details.

---

## ğŸ§  Technical Stack

- **Python 3.12+**
- **LLMs (Groq/OpenAI, via `src/llm/groq_client.py`)**
- **Prompt Engineering (custom templates)**
- **FastAPI/Flask (serving)**
- **Docker, Kubernetes, Jenkins**
- **Modern Python OOP & Pipeline Patterns**

---

## ğŸ—ï¸ Project Structure

```bash
LLMOPS-AIOPS-Project4-STUDY-BUDDY-AI/
â”œâ”€â”€ application.py                # FastAPI/Flask app entry point
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ common/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ custom_exception.py
â”‚   â”‚   â””â”€â”€ logger.py
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ settings.py
â”‚   â”œâ”€â”€ generator/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ question_generator.py        # Core question/content generator
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ groq_client.py               # LLM API client logic
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ question_schemas.py          # Pydantic models/schemas
â”‚   â”œâ”€â”€ prompts/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ templates.py                 # Prompt template logic
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ __init__.py
â”œâ”€â”€ manifests/
â”‚   â”œâ”€â”€ deployment.yaml                  # Kubernetes deployment
â”‚   â””â”€â”€ service.yaml                     # Kubernetes service
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ Jenkinsfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md
â”œâ”€â”€ FULL_DOCUMENTATION.md
```

---

## âš¡ Installation & Usage

### 1. Clone the repository
```bash
git clone https://github.com/mdzaheerjk/LLMOPS-AIOPS-Project4-STUDY-BUDDY-AI.git
cd LLMOPS-AIOPS-Project4-STUDY-BUDDY-AI
```

### 2. Set up a virtual environment
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 3. Install dependencies
```bash
pip install -r requirements.txt
```

### 4. Run the application
```bash
python application.py
```
Or build and run with Docker:
```bash
docker build -t study-buddy-ai .
docker run -p 8000:8000 study-buddy-ai
```

### 5. Kubernetes Deployment
Apply the manifests to your cluster:
```bash
kubectl apply -f manifests/deployment.yaml
kubectl apply -f manifests/service.yaml
```

### 6. CI/CD with Jenkins
See `Jenkinsfile` for pipeline stages. Integrate with your Jenkins server for automated build/test/deploy.

---

## ğŸ§ª Example Usage

- **Generate Study Questions:**  
  Input a topic or subject; get AI-generated questions or quizzes instantly.
- **Personalized Learning:**  
  Adaptive questions and explanations tailored to user level and topic.
- **API Demo or UI:**  
  Integrate as a backend for educational apps or chatbots.

---

## ğŸ“š Documentation

See [FULL_DOCUMENTATION.md](FULL_DOCUMENTATION.md) for technical deep-dive, API reference, and extensibility guide.

---

## âœï¸ Author

**Mohammed Zaheeruddin**  
ğŸ“ First-Year B.Tech Student | AI/ML & GenAI Enthusiast  
ğŸ« Shetty Institute of Technology, Gulbarga  
ğŸ“§ info.zaheerjk@gmail.com

---

## ğŸ“œ License

This project is licensed under the **GPL-3.0 License** â€“ see the LICENSE file for details.

---

#### Key Features:
1. LLM-powered, modular AI study assistant
2. Clean, extensible Python codebase with prompt engineering
3. Docker, Kubernetes, and Jenkins for production-ready deployment
4. Designed for education, research, and real-world learning platforms
